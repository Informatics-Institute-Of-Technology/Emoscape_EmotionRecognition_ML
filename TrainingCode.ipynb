{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TrainingCode.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iibATUYyYBB"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvRtNMdvywc9"
      },
      "source": [
        "#!unzip /content/drive/MyDrive/Dataset/train.zip\n",
        "#!unzip /content/drive/MyDrive/Dataset/validation.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBMMIC7ay0UO"
      },
      "source": [
        "# num of classes or emotions\n",
        "num_classes=5\n",
        "\n",
        "# size of the input image\n",
        "img_rows, img_cols =48,48\n",
        "\n",
        "# num of images supplied to the neural network per epoch\n",
        "batch_size=16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN35kowmy2Sh"
      },
      "source": [
        "train_data_dir='/content/train'\n",
        "validation_data_dir ='/content/validation'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6y72AOiy364"
      },
      "source": [
        "# augmenting the images to increase the dataset and increase the accuracy when trained\n",
        "# images are rotated, zoomed, flpped , height and width altered\n",
        "train_datagen= ImageDataGenerator(rescale=1./255,\n",
        "                                  rotation_range=30, \n",
        "                                  shear_range=0.3, \n",
        "                                  zoom_range=0.3, \n",
        "                                  width_shift_range=0.4, \n",
        "                                  height_shift_range=0.4, \n",
        "                                  horizontal_flip=True, \n",
        "                                  vertical_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt7aZRx_y5VE"
      },
      "source": [
        "validation_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk4T3qNjy8RH",
        "outputId": "7679360e-df9d-42fb-f621-62ff7c9de4cd"
      },
      "source": [
        "# generating or preparing the data to feed to the neural network for training by providing the image size, image color mode , shuffling the images\n",
        "train_generator=train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                  color_mode='grayscale',\n",
        "                                                  target_size=(img_rows,img_cols),\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24282 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F451ETrFy-K2",
        "outputId": "feaf0bb3-9195-4464-cf51-217d3e86802e"
      },
      "source": [
        "# generating or preparing the data for validation to check the accuracy of the model while it is being trained\n",
        "validation_generator=validation_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                  color_mode='grayscale',\n",
        "                                                  target_size=(img_rows,img_cols),\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5937 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDktd4PizBGm"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "#1st convolution layer\n",
        "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
        "\n",
        "# relu activation function will return the input directly if it is positive, otherwise it will return zero (images contains numeric pixel values)\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# distribution of the inputs to layers may change after each mini-batch when the weights are updated, batch normalisation standardizes the inputs to a layer for each mini-batch.\n",
        "# batch normalization stabilizes the learning process.\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# max pooling down samples the input by calculating and returning the maximum value in a patch.\n",
        "# highlights the most present feature and returns it.\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "#2nd convolution layer\n",
        "#increased the number of neurons for accuracy\n",
        "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#3rd convolution layer\n",
        "#increased the number of neurons for accuracy\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "#dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "#4th convolution layer\n",
        "#increased the number of neurons for accuracy\n",
        "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "#dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "#5th convolution layer\n",
        "#increased the number of neurons for accuracy\n",
        "model.add(Conv2D(512,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "#dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# flattening\n",
        "# convert all the pooled layers into a single column  \n",
        "model.add(Flatten())\n",
        "\n",
        "# fully connected layer\n",
        "# all neurons are connected to each other, each neuron in the dense layer receives input from all neurons of its previous layer\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# dense to the number of classes or emotions, to get the predictions or probabilities for each class.\n",
        "# Softmax calculates a probability for each class.\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdplcFN6zQOl"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2j9ITLpze5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf83510-cd3e-48f9-da1e-efb77dae6e47"
      },
      "source": [
        "\n",
        "#Compliling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "nb_train_samples = 24282\n",
        "nb_validation_samples = 5937\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "num_classes = 5\n",
        "\n",
        "\n",
        "#Training the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "\n",
        "#Saving the model\n",
        "model.save('Final_2_TrainedModel.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1517/1517 [==============================] - 25s 16ms/step - loss: 1.8555 - accuracy: 0.2462 - val_loss: 1.6646 - val_accuracy: 0.2668\n",
            "Epoch 2/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.6126 - accuracy: 0.2780 - val_loss: 1.6632 - val_accuracy: 0.3063\n",
            "Epoch 3/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.6025 - accuracy: 0.2706 - val_loss: 1.7648 - val_accuracy: 0.2780\n",
            "Epoch 4/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.5890 - accuracy: 0.2863 - val_loss: 1.5191 - val_accuracy: 0.3369\n",
            "Epoch 5/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.5360 - accuracy: 0.3090 - val_loss: 1.4155 - val_accuracy: 0.3782\n",
            "Epoch 6/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.4991 - accuracy: 0.3357 - val_loss: 1.4309 - val_accuracy: 0.4031\n",
            "Epoch 7/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.4568 - accuracy: 0.3625 - val_loss: 1.2758 - val_accuracy: 0.4695\n",
            "Epoch 8/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.4216 - accuracy: 0.3897 - val_loss: 1.3086 - val_accuracy: 0.4547\n",
            "Epoch 9/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.3877 - accuracy: 0.4069 - val_loss: 1.2822 - val_accuracy: 0.4530\n",
            "Epoch 10/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.3691 - accuracy: 0.4229 - val_loss: 1.1061 - val_accuracy: 0.5600\n",
            "Epoch 11/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.3448 - accuracy: 0.4323 - val_loss: 1.1162 - val_accuracy: 0.5490\n",
            "Epoch 12/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.3294 - accuracy: 0.4360 - val_loss: 1.0941 - val_accuracy: 0.5633\n",
            "Epoch 13/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2932 - accuracy: 0.4635 - val_loss: 1.1001 - val_accuracy: 0.5510\n",
            "Epoch 14/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.3012 - accuracy: 0.4538 - val_loss: 1.0543 - val_accuracy: 0.5758\n",
            "Epoch 15/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2737 - accuracy: 0.4680 - val_loss: 1.1051 - val_accuracy: 0.5581\n",
            "Epoch 16/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2791 - accuracy: 0.4657 - val_loss: 1.0433 - val_accuracy: 0.5807\n",
            "Epoch 17/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2573 - accuracy: 0.4807 - val_loss: 1.0615 - val_accuracy: 0.5750\n",
            "Epoch 18/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2523 - accuracy: 0.4842 - val_loss: 0.9956 - val_accuracy: 0.5994\n",
            "Epoch 19/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2528 - accuracy: 0.4822 - val_loss: 1.0303 - val_accuracy: 0.5846\n",
            "Epoch 20/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2455 - accuracy: 0.4843 - val_loss: 1.0086 - val_accuracy: 0.6044\n",
            "Epoch 21/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2212 - accuracy: 0.4969 - val_loss: 1.0389 - val_accuracy: 0.5930\n",
            "Epoch 22/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2222 - accuracy: 0.5006 - val_loss: 0.9719 - val_accuracy: 0.6189\n",
            "Epoch 23/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2264 - accuracy: 0.4958 - val_loss: 0.9884 - val_accuracy: 0.6023\n",
            "Epoch 24/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2118 - accuracy: 0.5019 - val_loss: 1.0393 - val_accuracy: 0.5874\n",
            "Epoch 25/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.2042 - accuracy: 0.5068 - val_loss: 1.0050 - val_accuracy: 0.6073\n",
            "Epoch 26/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1967 - accuracy: 0.5129 - val_loss: 0.9364 - val_accuracy: 0.6375\n",
            "Epoch 27/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1986 - accuracy: 0.5083 - val_loss: 1.0215 - val_accuracy: 0.5984\n",
            "Epoch 28/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1935 - accuracy: 0.5144 - val_loss: 0.9731 - val_accuracy: 0.6275\n",
            "Epoch 29/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1996 - accuracy: 0.5058 - val_loss: 0.9503 - val_accuracy: 0.6306\n",
            "Epoch 30/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1862 - accuracy: 0.5124 - val_loss: 0.9956 - val_accuracy: 0.6240\n",
            "Epoch 31/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1719 - accuracy: 0.5221 - val_loss: 0.9269 - val_accuracy: 0.6408\n",
            "Epoch 32/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1802 - accuracy: 0.5182 - val_loss: 0.9098 - val_accuracy: 0.6553\n",
            "Epoch 33/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1572 - accuracy: 0.5305 - val_loss: 0.9569 - val_accuracy: 0.6203\n",
            "Epoch 34/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1748 - accuracy: 0.5275 - val_loss: 0.9386 - val_accuracy: 0.6363\n",
            "Epoch 35/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1630 - accuracy: 0.5239 - val_loss: 0.9220 - val_accuracy: 0.6444\n",
            "Epoch 36/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1739 - accuracy: 0.5197 - val_loss: 0.9404 - val_accuracy: 0.6361\n",
            "Epoch 37/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1624 - accuracy: 0.5317 - val_loss: 0.9994 - val_accuracy: 0.6095\n",
            "Epoch 38/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1649 - accuracy: 0.5274 - val_loss: 0.9835 - val_accuracy: 0.6173\n",
            "Epoch 39/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1617 - accuracy: 0.5216 - val_loss: 0.9103 - val_accuracy: 0.6504\n",
            "Epoch 40/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1587 - accuracy: 0.5345 - val_loss: 0.8915 - val_accuracy: 0.6568\n",
            "Epoch 41/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1501 - accuracy: 0.5332 - val_loss: 0.9070 - val_accuracy: 0.6501\n",
            "Epoch 42/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1596 - accuracy: 0.5287 - val_loss: 0.8889 - val_accuracy: 0.6644\n",
            "Epoch 43/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1409 - accuracy: 0.5354 - val_loss: 0.9202 - val_accuracy: 0.6418\n",
            "Epoch 44/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1388 - accuracy: 0.5382 - val_loss: 0.8834 - val_accuracy: 0.6573\n",
            "Epoch 45/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1328 - accuracy: 0.5416 - val_loss: 0.9198 - val_accuracy: 0.6456\n",
            "Epoch 46/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1509 - accuracy: 0.5300 - val_loss: 0.8711 - val_accuracy: 0.6701\n",
            "Epoch 47/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1480 - accuracy: 0.5341 - val_loss: 0.8973 - val_accuracy: 0.6521\n",
            "Epoch 48/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1441 - accuracy: 0.5364 - val_loss: 0.8702 - val_accuracy: 0.6727\n",
            "Epoch 49/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1311 - accuracy: 0.5416 - val_loss: 0.9008 - val_accuracy: 0.6526\n",
            "Epoch 50/50\n",
            "1517/1517 [==============================] - 23s 15ms/step - loss: 1.1296 - accuracy: 0.5475 - val_loss: 0.8884 - val_accuracy: 0.6535\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}