{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TrainingCode.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iibATUYyYBB"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvRtNMdvywc9"
      },
      "source": [
        "#!unzip /content/drive/MyDrive/Dataset/train.zip\n",
        "#!unzip /content/drive/MyDrive/Dataset/validation.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBMMIC7ay0UO"
      },
      "source": [
        "# num of classes or emotions\n",
        "num_classes=5\n",
        "\n",
        "# size of the input image\n",
        "img_rows, img_cols =48,48\n",
        "\n",
        "# num of images supplied to the neural network per epoch\n",
        "batch_size=16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN35kowmy2Sh"
      },
      "source": [
        "train_data_dir='/content/train'\n",
        "validation_data_dir ='/content/validation'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6y72AOiy364"
      },
      "source": [
        "# augmenting the images to increase the dataset and increase the accuracy when trained\n",
        "# images are rotated, zoomed, flpped , height and width altered\n",
        "train_datagen= ImageDataGenerator(rescale=1./255,\n",
        "                                  rotation_range=30, \n",
        "                                  shear_range=0.3, \n",
        "                                  zoom_range=0.3, \n",
        "                                  width_shift_range=0.4, \n",
        "                                  height_shift_range=0.4, \n",
        "                                  horizontal_flip=True, \n",
        "                                  vertical_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt7aZRx_y5VE"
      },
      "source": [
        "validation_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk4T3qNjy8RH",
        "outputId": "2b1b0764-5b2f-4349-9fa5-8fcf48f24ef6"
      },
      "source": [
        "# generating or preparing the data to feed to the neural network for training by providing the image size, image color mode , shuffling the images\n",
        "train_generator=train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                  color_mode='grayscale',\n",
        "                                                  target_size=(img_rows,img_cols),\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24282 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F451ETrFy-K2",
        "outputId": "f8b384af-a8fe-4dc7-b611-6ae0fcd35a85"
      },
      "source": [
        "# generating or preparing the data for validation to check the accuracy of the model while it is being trained\n",
        "validation_generator=validation_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                  color_mode='grayscale',\n",
        "                                                  target_size=(img_rows,img_cols),\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5937 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDktd4PizBGm"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "#1st convolution layer\n",
        "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
        "\n",
        "# relu activation function will return the input directly if it is positive, otherwise it will return zero (images contains numeric pixel values)\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# distribution of the inputs to layers may change after each mini-batch when the weights are updated, batch normalisation standardizes the inputs to a layer for each mini-batch.\n",
        "# batch normalization stabilizes the learning process.\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# max pooling down samples the input by calculating and returning the maximum value in a patch.\n",
        "# highlights the most present feature and returns it.\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "#2nd convolution layer\n",
        "#increased the number of neurons for accuracy\n",
        "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#3rd convolution layer\n",
        "#increased the number of neurons for accuracy\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "#dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "#4th convolution layer\n",
        "#increased the number of neurons for accuracy\n",
        "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "#dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "#5th convolution layer\n",
        "#increased the number of neurons for accuracy\n",
        "model.add(Conv2D(512,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "#dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# flattening\n",
        "# convert all the pooled layers into a single column  \n",
        "model.add(Flatten())\n",
        "\n",
        "# fully connected layer\n",
        "# all neurons are connected to each other, each neuron in the dense layer receives input from all neurons of its previous layer\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# dense to the number of classes or emotions, to get the predictions or probabilities for each class.\n",
        "# Softmax calculates a probability for each class.\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdplcFN6zQOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4172244-6efb-471e-b589-1d71996ba88d"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 48, 48, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 48, 48, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 3, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 1, 1, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 1,709,573\n",
            "Trainable params: 1,705,093\n",
            "Non-trainable params: 4,480\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2j9ITLpze5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26a374a-3b80-4c64-a50f-98639f571c5b"
      },
      "source": [
        "\n",
        "#Compliling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "nb_train_samples = 24282\n",
        "nb_validation_samples = 5937\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "num_classes = 5\n",
        "\n",
        "\n",
        "#Training the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "\n",
        "#Saving the model\n",
        "model.save('TrainedModel_20_04_2021.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1517/1517 [==============================] - 58s 16ms/step - loss: 1.7640 - accuracy: 0.2545 - val_loss: 1.8262 - val_accuracy: 0.2653\n",
            "Epoch 2/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.5978 - accuracy: 0.2639 - val_loss: 1.6010 - val_accuracy: 0.3041\n",
            "Epoch 3/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.5740 - accuracy: 0.2835 - val_loss: 1.5606 - val_accuracy: 0.3100\n",
            "Epoch 4/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.5543 - accuracy: 0.2986 - val_loss: 1.6614 - val_accuracy: 0.2906\n",
            "Epoch 5/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.5133 - accuracy: 0.3267 - val_loss: 1.3896 - val_accuracy: 0.3988\n",
            "Epoch 6/50\n",
            "1517/1517 [==============================] - 25s 16ms/step - loss: 1.4727 - accuracy: 0.3522 - val_loss: 1.3216 - val_accuracy: 0.4308\n",
            "Epoch 7/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.4362 - accuracy: 0.3786 - val_loss: 1.4044 - val_accuracy: 0.4323\n",
            "Epoch 8/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.4057 - accuracy: 0.3905 - val_loss: 1.1894 - val_accuracy: 0.5207\n",
            "Epoch 9/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.3855 - accuracy: 0.4097 - val_loss: 1.1564 - val_accuracy: 0.5391\n",
            "Epoch 10/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.3542 - accuracy: 0.4243 - val_loss: 1.2327 - val_accuracy: 0.5125\n",
            "Epoch 11/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.3372 - accuracy: 0.4330 - val_loss: 1.0923 - val_accuracy: 0.5571\n",
            "Epoch 12/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.3234 - accuracy: 0.4445 - val_loss: 1.0710 - val_accuracy: 0.5711\n",
            "Epoch 13/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.3036 - accuracy: 0.4540 - val_loss: 1.1376 - val_accuracy: 0.5399\n",
            "Epoch 14/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.3026 - accuracy: 0.4486 - val_loss: 1.0318 - val_accuracy: 0.5837\n",
            "Epoch 15/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.2833 - accuracy: 0.4593 - val_loss: 1.1321 - val_accuracy: 0.5556\n",
            "Epoch 16/50\n",
            "1517/1517 [==============================] - 25s 16ms/step - loss: 1.2619 - accuracy: 0.4782 - val_loss: 1.0607 - val_accuracy: 0.5785\n",
            "Epoch 17/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.2590 - accuracy: 0.4749 - val_loss: 1.0306 - val_accuracy: 0.5765\n",
            "Epoch 18/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.2499 - accuracy: 0.4812 - val_loss: 1.0799 - val_accuracy: 0.5623\n",
            "Epoch 19/50\n",
            "1517/1517 [==============================] - 25s 16ms/step - loss: 1.2498 - accuracy: 0.4787 - val_loss: 1.0745 - val_accuracy: 0.5686\n",
            "Epoch 20/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.2391 - accuracy: 0.4896 - val_loss: 0.9965 - val_accuracy: 0.6039\n",
            "Epoch 21/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.2279 - accuracy: 0.4898 - val_loss: 1.0012 - val_accuracy: 0.6006\n",
            "Epoch 22/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.2127 - accuracy: 0.4970 - val_loss: 0.9575 - val_accuracy: 0.6228\n",
            "Epoch 23/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.2129 - accuracy: 0.5032 - val_loss: 1.0152 - val_accuracy: 0.6011\n",
            "Epoch 24/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.2109 - accuracy: 0.4997 - val_loss: 0.9560 - val_accuracy: 0.6267\n",
            "Epoch 25/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.2184 - accuracy: 0.4972 - val_loss: 0.9921 - val_accuracy: 0.6088\n",
            "Epoch 26/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1971 - accuracy: 0.5086 - val_loss: 1.0357 - val_accuracy: 0.5896\n",
            "Epoch 27/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1992 - accuracy: 0.5163 - val_loss: 0.9220 - val_accuracy: 0.6331\n",
            "Epoch 28/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1940 - accuracy: 0.5131 - val_loss: 0.9525 - val_accuracy: 0.6314\n",
            "Epoch 29/50\n",
            "1517/1517 [==============================] - 25s 16ms/step - loss: 1.1829 - accuracy: 0.5118 - val_loss: 0.9581 - val_accuracy: 0.6205\n",
            "Epoch 30/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1910 - accuracy: 0.5165 - val_loss: 0.9355 - val_accuracy: 0.6312\n",
            "Epoch 31/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1795 - accuracy: 0.5209 - val_loss: 0.9685 - val_accuracy: 0.6124\n",
            "Epoch 32/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1786 - accuracy: 0.5191 - val_loss: 0.9328 - val_accuracy: 0.6376\n",
            "Epoch 33/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1813 - accuracy: 0.5199 - val_loss: 0.9282 - val_accuracy: 0.6392\n",
            "Epoch 34/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1712 - accuracy: 0.5242 - val_loss: 0.9682 - val_accuracy: 0.6127\n",
            "Epoch 35/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1703 - accuracy: 0.5246 - val_loss: 0.9546 - val_accuracy: 0.6282\n",
            "Epoch 36/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1547 - accuracy: 0.5337 - val_loss: 0.9318 - val_accuracy: 0.6319\n",
            "Epoch 37/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1693 - accuracy: 0.5245 - val_loss: 0.9158 - val_accuracy: 0.6471\n",
            "Epoch 38/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1703 - accuracy: 0.5230 - val_loss: 1.0053 - val_accuracy: 0.5965\n",
            "Epoch 39/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1694 - accuracy: 0.5241 - val_loss: 0.9434 - val_accuracy: 0.6312\n",
            "Epoch 40/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1566 - accuracy: 0.5319 - val_loss: 0.8932 - val_accuracy: 0.6555\n",
            "Epoch 41/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1617 - accuracy: 0.5256 - val_loss: 0.9178 - val_accuracy: 0.6454\n",
            "Epoch 42/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1568 - accuracy: 0.5265 - val_loss: 0.9071 - val_accuracy: 0.6474\n",
            "Epoch 43/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1520 - accuracy: 0.5330 - val_loss: 0.9225 - val_accuracy: 0.6439\n",
            "Epoch 44/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1442 - accuracy: 0.5377 - val_loss: 0.9399 - val_accuracy: 0.6321\n",
            "Epoch 45/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1541 - accuracy: 0.5271 - val_loss: 0.9043 - val_accuracy: 0.6388\n",
            "Epoch 46/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1465 - accuracy: 0.5344 - val_loss: 0.9293 - val_accuracy: 0.6358\n",
            "Epoch 47/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1531 - accuracy: 0.5308 - val_loss: 0.8798 - val_accuracy: 0.6555\n",
            "Epoch 48/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1431 - accuracy: 0.5394 - val_loss: 0.8818 - val_accuracy: 0.6533\n",
            "Epoch 49/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1369 - accuracy: 0.5412 - val_loss: 0.9188 - val_accuracy: 0.6417\n",
            "Epoch 50/50\n",
            "1517/1517 [==============================] - 24s 16ms/step - loss: 1.1466 - accuracy: 0.5407 - val_loss: 0.8694 - val_accuracy: 0.6594\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}